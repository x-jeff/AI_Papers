# AI_Papers

|åºå·|è®ºæ–‡é¢˜ç›®|å…³é”®å­—|åŸæ–‡|åšå®¢è®²è§£|
|:-:|:-:|:-:|:-:|:-:|
|1|Gradient-Based Learning Applied to Document Recognition|LeNet5|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Gradient-Based%20Learning%20Applied%20to%20Document.pdf)|[ğŸ”—](http://shichaoxin.com/2020/10/13/è®ºæ–‡é˜…è¯»-Gradient-Based-Learning-Applied-to-Document-Recognition/)|
|2|ImageNet Classification with Deep Convolutional Neural Networks|AlexNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/ImageNet%20Classification%20with%20Deep%20Convolutional%20Neural%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2021/02/03/è®ºæ–‡é˜…è¯»-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/)|
|3|VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION|VGGNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/VERY%20DEEP%20CONVOLUTIONAL%20NETWORKS%20FOR%20LARGE-SCALE%20IMAGE%20RECOGNITION.pdf)|[ğŸ”—](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)|
|4|Visualizing and Understanding Convolutional Networks|ZFNetï¼Œå·ç§¯ç½‘ç»œå¯è§†åŒ–ï¼Œåå·ç§¯ç½‘ç»œ|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Visualizing%20and%20Understanding%20Convolutional%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2021/05/02/è®ºæ–‡é˜…è¯»-Visualizing-and-Understanding-Convolutional-Networks/)|
|5|Going deeper with convolutions|GoogLeNetï¼ŒInception-v1|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Going%20deeper%20with%20convolutions.pdf)|[ğŸ”—](http://shichaoxin.com/2021/06/01/è®ºæ–‡é˜…è¯»-Going-deeper-with-convolutions/)|
|6|Rich feature hierarchies for accurate object detection and semantic segmentation|R-CNN|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Rich%20feature%20hierarchies%20for%20accurate%20object%20detection%20and%20semantic%20segmentation.pdf)|[ğŸ”—](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)|
|7|Generative Adversarial Nets|GAN|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Generative%20Adversarial%20Nets.pdf)|[ğŸ”—](http://shichaoxin.com/2021/10/30/è®ºæ–‡é˜…è¯»-Generative-Adversarial-Nets/)|
|8|Selective Search for Object Recognition|Selective Searchç®—æ³•|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Selective%20Search%20for%20Object%20Recognition.pdf)|[ğŸ”—](http://shichaoxin.com/2021/10/16/è®ºæ–‡é˜…è¯»-Selective-Search-for-Object-Recognition/)|
|9|Efficient Graph-Based Image Segmentation|NULL|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Efficient%20Graph-Based%20Image%20Segmentation.pdf)|[ğŸ”—](http://shichaoxin.com/2021/10/19/è®ºæ–‡é˜…è¯»-Efficient-Graph-Based-Image-Segmentation/)|
|10|Batch Normalizationï¼šAccelerating Deep Network Training by Reducing Internal Covariate Shift|Batch Normalizationï¼ŒBN-Inception|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Batch%20Normalizationï¼šAccelerating%20Deep%20Network%20Training%20by%20Reducing%20Internal%20Covariate%20Shift.pdf)|[ğŸ”—](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)|
|11|Interactive Graph Cuts for Optimal Boundary & Region Segmentation of Objects in N-D Images|GraphCutç®—æ³•|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Interactive%20Graph%20Cuts%20for%20Optimal%20Boundary%20%26%20Region%20Segmentation%20of%20Objects%20in%20N-D%20Images.pdf)|[ğŸ”—](http://shichaoxin.com/2018/10/21/å›¾åƒåˆ†å‰²-Graph-Cutç®—æ³•/)|
|12|â€œGrabCutâ€ â€” Interactive Foreground Extraction using Iterated Graph Cuts|GrabCutç®—æ³•|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/â€œGrabCutâ€%20â€”%20Interactive%20Foreground%20Extraction%20using%20Iterated%20Graph%20Cuts.pdf)|[ğŸ”—](http://shichaoxin.com/2018/11/04/å›¾åƒåˆ†å‰²-GrabCutç®—æ³•/)|
|13|Topological Structural Analysis of Digitized Binary Images by Border Following|Border Followingï¼Œcv::findContoursåŸç†|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Topological%20Structural%20Analysis%20of%20Digitized%20Binary%20Images%20by%20Border%20Following.pdf)|[ğŸ”—](http://shichaoxin.com/2021/12/03/æ–‡çŒ®é˜…è¯»-Topological-Structural-Analysis-of-Digitized-Binary-Images-by-Border-Following/)|
|14|Rethinking the Inception Architecture for Computer Vision|Inception-v2ï¼ŒInception-v3|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Rethinking%20the%20Inception%20Architecture%20for%20Computer%20Vision.pdf)|[ğŸ”—](http://shichaoxin.com/2021/11/29/è®ºæ–‡é˜…è¯»-Rethinking-the-Inception-Architecture-for-Computer-Vision/)|
|15|U-Net: Convolutional Networks for Biomedical Image Segmentation|U-Net|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/U-Net%20Convolutional%20Networks%20for%20Biomedical%20Image%20Segmentation.pdf)|[ğŸ”—](http://shichaoxin.com/2022/03/05/è®ºæ–‡é˜…è¯»-U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation/)|
|16|Fully Convolutional Networks for Semantic Segmentation|FCNï¼Œshift-and-stitchï¼Œbackwards convolutionï¼Œdeconvolution|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Fully%20Convolutional%20Networks%20for%20Semantic%20Segmentation.pdf)|[ğŸ”—](http://shichaoxin.com/2022/01/31/è®ºæ–‡é˜…è¯»-Fully-Convolutional-Networks-for-Semantic-Segmentation/)|
|17|Deep Residual Learning for Image Recognition|ResNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Deep%20Residual%20Learning%20for%20Image%20Recognition.pdf)|[ğŸ”—](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)|
|18|Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning|Inception-v4ï¼ŒInception-ResNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Inception-v4%2C%20Inception-ResNet%20and%20the%20Impact%20of%20Residual%20Connections%20on%20Learning.pdf)|[ğŸ”—](http://shichaoxin.com/2022/01/13/è®ºæ–‡é˜…è¯»-Inception-v4,-Inception-ResNet-and-the-Impact-of-Residual-Connections-on-Learning/)|
|19|Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition|SPP-net|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Spatial%20Pyramid%20Pooling%20in%20Deep%20Convolutional%20Networks%20for%20Visual%20Recognition.pdf)|[ğŸ”—](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)|
|20|Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis|Elastic Distortions|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Best%20Practices%20for%20Convolutional%20Neural%20Networks%20Applied%20to%20Visual%20Document%20Analysis.pdf)|[ğŸ”—](http://shichaoxin.com/2022/03/01/è®ºæ–‡é˜…è¯»-Best-Practices-for-Convolutional-Neural-Networks-Applied-to-Visual-Document-Analysis/)|
|21|Fast R-CNN|Fast R-CNN|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Fast%20R-CNN.pdf)|[ğŸ”—](http://shichaoxin.com/2022/03/07/è®ºæ–‡é˜…è¯»-Fast-R-CNN/)|
|22|Layer Normalization|Layer Normalization|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Layer%20Normalization.pdf)|[ğŸ”—](http://shichaoxin.com/2022/03/19/è®ºæ–‡é˜…è¯»-Layer-Normalization/)|
|23|Attention Is All You Need|Transformerï¼ŒMulti-Head Attention|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Attention%20Is%20All%20You%20Need.pdf)|[ğŸ”—](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/)|
|24|Faster R-CNNï¼šTowards Real-Time Object Detection with Region Proposal Networks|Faster R-CNNï¼ŒRegion Proposal Networksï¼ˆRPNï¼‰|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Faster%20R-CNNï¼šTowards%20Real-Time%20Object%20Detection%20with%20Region%20Proposal%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2022/04/03/è®ºæ–‡é˜…è¯»-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)|
|25|FAST AND ACCURATE DEEP NETWORK LEARNING BY EXPONENTIAL LINEAR UNITS (ELUS)|exponential linear unitï¼ˆELUï¼‰æ¿€æ´»å‡½æ•°ï¼ŒShifted ReLUï¼ˆSReLUï¼‰æ¿€æ´»å‡½æ•°|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Fast%20and%20Accurate%20Deep%20Network%20Learning%20by%20Exponential%20Linear%20Units%20(ELUs).pdf)|[ğŸ”—](http://shichaoxin.com/2022/04/08/è®ºæ–‡é˜…è¯»-FAST-AND-ACCURATE-DEEP-NETWORK-LEARNING-BY-EXPONENTIAL-LINEAR-UNITS-(ELUS)/)|
|26|GAUSSIAN ERROR LINEAR UNITS (GELUS)|Gaussian Error Linear Unitï¼ˆGELUï¼‰æ¿€æ´»å‡½æ•°ï¼ŒSigmoid Linear Unitï¼ˆSiLUï¼‰æ¿€æ´»å‡½æ•°|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/GAUSSIAN%20ERROR%20LINEAR%20UNITS%20(GELUS).pdf)|[ğŸ”—](http://shichaoxin.com/2022/04/09/è®ºæ–‡é˜…è¯»-GAUSSIAN-ERROR-LINEAR-UNITS-(GELUS)/)|
|27|You Only Look Onceï¼š Unified, Real-Time Object Detection|YOLOv1|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/You%20Only%20Look%20Onceï¼š%20Unified%2C%20Real-Time%20Object%20Detection.pdf)|[ğŸ”—](http://shichaoxin.com/2022/05/11/è®ºæ–‡é˜…è¯»-You-Only-Look-Once-Unified,-Real-Time-Object-Detection/)|
|28|YOLO9000ï¼šBetter, Faster, Stronger|YOLOv2ï¼ŒYOLO9000|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/YOLO9000ï¼š%20Better%2C%20Faster%2C%20Stronger.pdf)|[ğŸ”—](http://shichaoxin.com/2022/06/01/è®ºæ–‡é˜…è¯»-YOLO9000-Better,-Faster,-Stronger/)|
|29|YOLOv3ï¼šAn Incremental Improvement|YOLOv3ï¼ŒDarknet-53|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/YOLOv3ï¼šAn%20Incremental%20Improvement.pdf)|[ğŸ”—](http://shichaoxin.com/2022/06/29/è®ºæ–‡é˜…è¯»-YOLOv3-An-Incremental-Improvement/)|
|30|AN IMAGE IS WORTH 16X16 WORDSï¼šTRANSFORMERS FOR IMAGE RECOGNITION AT SCALE|Vision Transformerï¼ˆViTï¼‰|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/AN%20IMAGE%20IS%20WORTH%2016X16%20WORDSï¼š%20TRANSFORMERS%20FOR%20IMAGE%20RECOGNITION%20AT%20SCALE.pdf)|[ğŸ”—](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)|
|31|Distribution-Aware Coordinate Representation for Human Pose Estimation|DARK|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Distribution-Aware%20Coordinate%20Representation%20for%20Human%20Pose%20Estimation.pdf)|[ğŸ”—](http://shichaoxin.com/2022/10/27/è®ºæ–‡é˜…è¯»-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/)|
|32|ViTPoseï¼šSimple Vision Transformer Baselines for Human Pose Estimation|ViTPoseï¼ŒHuman Pose Estimation|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/ViTPoseï¼šSimple%20Vision%20Transformer%20Baselines%20for%20Human%20Pose%20Estimation.pdf)|[ğŸ”—](http://shichaoxin.com/2022/11/06/è®ºæ–‡é˜…è¯»-ViTPose-Simple-Vision-Transformer-Baselines-for-Human-Pose-Estimation/)|
|33|Swin Transformerï¼šHierarchical Vision Transformer using Shifted Windows|Swin Transformer|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Swin%20Transformerï¼šHierarchical%20Vision%20Transformer%20using%20Shifted%20Windows.pdf)|[ğŸ”—](http://shichaoxin.com/2022/11/22/è®ºæ–‡é˜…è¯»-Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows/)|
|34|Deep High-Resolution Representation Learning for Visual Recognition|HRNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Deep%20High-Resolution%20Representation%20Learning%20for%20Visual%20Recognition.pdf)|[ğŸ”—](http://shichaoxin.com/2023/05/13/è®ºæ–‡é˜…è¯»-Deep-High-Resolution-Representation-Learning-for-Visual-Recognition/)|
|35|FlowNetï¼šLearning Optical Flow with Convolutional Networks|FlowNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/FlowNetï¼šLearning%20Optical%20Flow%20with%20Convolutional%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2023/07/03/è®ºæ–‡é˜…è¯»-FlowNet-Learning-Optical-Flow-with-Convolutional-Networks/)|
|36|FlowNet 2.0ï¼šEvolution of Optical Flow Estimation with Deep Networks|FlowNet2|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/FlowNet%202.0ï¼šEvolution%20of%20Optical%20Flow%20Estimation%20with%20Deep%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2023/07/10/è®ºæ–‡é˜…è¯»-FlowNet-2.0-Evolution-of-Optical-Flow-Estimation-with-Deep-Networks/)|
|37|3D Convolutional Neural Networks for Human Action Recognition|3Då·ç§¯|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/3D%20Convolutional%20Neural%20Networks%20for%20Human%20Action%20Recognition.pdf)|[ğŸ”—](http://shichaoxin.com/2023/07/22/è®ºæ–‡é˜…è¯»-3D-Convolutional-Neural-Networks-for-Human-Action-Recognition/)|
|38|3D U-Netï¼šLearning Dense Volumetric Segmentation from Sparse Annotation|3D U-Net|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/3D%20U-Netï¼šLearning%20Dense%20Volumetric%20Segmentation%20from%20Sparse%20Annotation.pdf)|[ğŸ”—](http://shichaoxin.com/2023/07/22/è®ºæ–‡é˜…è¯»-3D-U-Net-Learning-Dense-Volumetric-Segmentation-from-Sparse-Annotation/)|
|39|V-Netï¼šFully Convolutional Neural Networks for Volumetric Medical Image Segmentation|V-Netï¼Œdice loss|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/V-Netï¼šFully%20Convolutional%20Neural%20Networks%20for%20Volumetric%20Medical%20Image%20Segmentation.pdf)|[ğŸ”—](http://shichaoxin.com/2023/08/01/è®ºæ–‡é˜…è¯»-V-Net-Fully-Convolutional-Neural-Networks-for-Volumetric-Medical-Image-Segmentation/)|
|40|SURFï¼šSpeeded Up Robust Features|SURFï¼ŒU-SURF|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/SURFï¼šSpeeded%20Up%20Robust%20Features.pdf)|[ğŸ”—](http://shichaoxin.com/2023/08/18/è®ºæ–‡é˜…è¯»-SURF-Speeded-Up-Robust-Features/)|
|41|nnU-Netï¼šSelf-adapting Framework for U-Net-Based Medical Image Segmentation|nnU-Net|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/nnU-Netï¼šSelf-adapting%20Framework%20for%20U-Net-Based%20Medical%20Image%20Segmentation.pdf)|[ğŸ”—](http://shichaoxin.com/2023/08/24/è®ºæ–‡é˜…è¯»-nnU-Net-Self-adapting-Framework-for-U-Net-Based-Medical-Image-Segmentation/)|
|42|Histograms of Oriented Gradients for Human Detection|HOG|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Histograms%20of%20Oriented%20Gradients%20for%20Human%20Detection.pdf)|[ğŸ”—](http://shichaoxin.com/2023/09/16/è®ºæ–‡é˜…è¯»-Histograms-of-Oriented-Gradients-for-Human-Detection/)|
|43|PERCEIVER IOï¼šA GENERAL ARCHITECTURE FOR STRUCTURED INPUTS & OUTPUTS|Perceiver IO|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/PERCEIVER%20IOï¼šA%20GENERAL%20ARCHITECTURE%20FOR%20STRUCTURED%20INPUTS%20%26%20OUTPUTS.pdf)|[ğŸ”—](http://shichaoxin.com/2023/10/24/è®ºæ–‡é˜…è¯»-PERCEIVER-IO-A-GENERAL-ARCHITECTURE-FOR-STRUCTURED-INPUTS-&-OUTPUTS/)|
|44|Densely Connected Convolutional Networks|DenseNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Densely%20Connected%20Convolutional%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2023/11/12/è®ºæ–‡é˜…è¯»-Densely-Connected-Convolutional-Networks/)|
|45|SimCCï¼ša Simple Coordinate Classification Perspective for Human Pose Estimation|SimCC|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/SimCCï¼ša%20Simple%20Coordinate%20Classification%20Perspective%20for%20Human%20Pose%20Estimation.pdf)|[ğŸ”—](http://shichaoxin.com/2023/12/08/è®ºæ–‡é˜…è¯»-SimCC-a-Simple-Coordinate-Classification-Perspective-for-Human-Pose-Estimation/)|
|46|Network In Network|NIN|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Network%20In%20Network.pdf)|[ğŸ”—](http://shichaoxin.com/2023/12/10/è®ºæ–‡é˜…è¯»-Network-In-Network/)|
|47|Aggregated Residual Transformations for Deep Neural Networks|ResNeXt|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Aggregated%20Residual%20Transformations%20for%20Deep%20Neural%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2023/12/11/è®ºæ–‡é˜…è¯»-Aggregated-Residual-Transformations-for-Deep-Neural-Networks/)|
|48|CSPNETï¼šA NEW BACKBONE THAT CAN ENHANCE LEARNING CAPABILITY OF CNN|CSPNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/CSPNETï¼šA%20NEW%20BACKBONE%20THAT%20CAN%20ENHANCE%20LEARNING%20CAPABILITY%20OF%20CNN.pdf)|[ğŸ”—](http://shichaoxin.com/2023/12/16/è®ºæ–‡é˜…è¯»-CSPNET-A-NEW-BACKBONE-THAT-CAN-ENHANCE-LEARNING-CAPABILITY-OF-CNN/)|
|49|Feature Pyramid Networks for Object Detection|FPN|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Feature%20Pyramid%20Networks%20for%20Object%20Detection.pdf)|[ğŸ”—](http://shichaoxin.com/2023/12/19/è®ºæ–‡é˜…è¯»-Feature-Pyramid-Networks-for-Object-Detection/)|
|50|Mask R-CNN|Mask R-CNN|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Mask%20R-CNN.pdf)|[ğŸ”—](http://shichaoxin.com/2023/12/25/è®ºæ–‡é˜…è¯»-Mask-R-CNN/)|
|51|Path Aggregation Network for Instance Segmentation|PANet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Path%20Aggregation%20Network%20for%20Instance%20Segmentation.pdf)|[ğŸ”—](http://shichaoxin.com/2023/12/28/è®ºæ–‡é˜…è¯»-Path-Aggregation-Network-for-Instance-Segmentation/)|
|52|YOLOv4ï¼šOptimal Speed and Accuracy of Object Detection|YOLOv4|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/YOLOv4ï¼šOptimal%20Speed%20and%20Accuracy%20of%20Object%20Detection.pdf)|[ğŸ”—](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)|
|53|YOLOv5|YOLOv5|`\`|[ğŸ”—](http://shichaoxin.com/2024/01/14/YOLOç³»åˆ—-YOLOv5/)|
|54|YOLOXï¼šExceeding YOLO Series in 2021|YOLOX|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/YOLOXï¼šExceeding%20YOLO%20Series%20in%202021.pdf)|[ğŸ”—](http://shichaoxin.com/2024/01/19/è®ºæ–‡é˜…è¯»-YOLOX-Exceeding-YOLO-Series-in-2021/)|
|55|Focal Loss for Dense Object Detection|Focal Lossï¼ŒRetinaNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Focal%20Loss%20for%20Dense%20Object%20Detection.pdf)|[ğŸ”—](http://shichaoxin.com/2024/02/22/è®ºæ–‡é˜…è¯»-Focal-Loss-for-Dense-Object-Detection/)|
|56|RTMDetï¼šAn Empirical Study of Designing Real-Time Object Detectors|RTMDet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/RTMDetï¼šAn%20Empirical%20Study%20of%20Designing%20Real-Time%20Object%20Detectors.pdf)|[ğŸ”—](http://shichaoxin.com/2024/02/25/è®ºæ–‡é˜…è¯»-RTMDet-An-Empirical-Study-of-Designing-Real-Time-Object-Detectors/)|
|57|RTMPoseï¼šReal-Time Multi-Person Pose Estimation based on MMPose|RTMPose|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/RTMPoseï¼šReal-Time%20Multi-Person%20Pose%20Estimation%20based%20on%20MMPose.pdf)|[ğŸ”—](http://shichaoxin.com/2024/02/25/è®ºæ–‡é˜…è¯»-RTMPose-Real-Time-Multi-Person-Pose-Estimation-based-on-MMPose/)|
|58|Effective Whole-body Pose Estimation with Two-stages Distillation|DWPose|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/Effective%20Whole-body%20Pose%20Estimation%20with%20Two-stages%20Distillation.pdf)|[ğŸ”—](http://shichaoxin.com/2024/02/25/è®ºæ–‡é˜…è¯»-Effective-Whole-body-Pose-Estimation-with-Two-stages-Distillation/)|
|59|OpenPoseï¼šRealtime Multi-Person 2D Pose Estimation using Part Affinity Fields|OpenPose|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/OpenPoseï¼šRealtime%20Multi-Person%202D%20Pose%20Estimation%20using%20Part%20Affinity%20Fields.pdf)|[ğŸ”—](http://shichaoxin.com/2024/03/10/è®ºæ–‡é˜…è¯»-OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/)|
|60|GPTç³»åˆ—è®ºæ–‡|GPT1ï¼ŒGPT2ï¼ŒGPT3ï¼ŒGPT3.5ï¼ŒInstructGPTï¼ŒGPT4|[ğŸ”—](https://github.com/x-jeff/AI_Papers/tree/master/2024/GPT)|[ğŸ”—](http://shichaoxin.com/2024/03/20/LLM-ä¸€æ–‡è¯»æ‡‚ChatGPTèƒŒåçš„æŠ€æœ¯/)|
|61|Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation|SCAI|[ğŸ”—](https://github.com/x-jeff/AI_Papers/tree/master/2024/SCAI)|[ğŸ”—](http://shichaoxin.com/2024/05/29/è®ºæ–‡é˜…è¯»-Self-Correctable-and-Adaptable-Inference-for-Generalizable-Human-Pose-Estimation/)|
|62|Simple Baselines for Human Pose Estimation and Tracking|SimpleBaseline|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/Simple%20Baselines%20for%20Human%20Pose%20Estimation%20and%20Tracking.pdf)|[ğŸ”—](http://shichaoxin.com/2024/05/29/è®ºæ–‡é˜…è¯»-Simple-Baselines-for-Human-Pose-Estimation-and-Tracking/)|
|63|TaG-Netï¼šTopology-Aware Graph Network for Centerline-Based Vessel Labeling|TaG-Netï¼Œvessel labelingï¼Œvessel segmentation|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/TaG-Netï¼šTopology-Aware%20Graph%20Network%20for%20Centerline-Based%20Vessel%20Labeling.pdf)|[ğŸ”—](http://shichaoxin.com/2024/06/22/è®ºæ–‡é˜…è¯»-TaG-Net-Topology-Aware-Graph-Network-for-Centerline-Based-Vessel-Labeling/)|
|64|OverFeatï¼šIntegrated Recognition, Localization and Detection using Convolutional Networks|OverFeatï¼Œsliding window|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/OverFeatï¼šIntegrated%20Recognition%2C%20Localization%20and%20Detection%20using%20Convolutional%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2024/06/29/è®ºæ–‡é˜…è¯»-OverFeat-Integrated-Recognition,-Localization-and-Detection-using-Convolutional-Networks/)|
|65|Bag of Tricks for Image Classification with Convolutional Neural Networks|ResNet-vcï¼ŒResNet-vd|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/Bag%20of%20Tricks%20for%20Image%20Classification%20with%20Convolutional%20Neural%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2024/07/10/è®ºæ–‡é˜…è¯»-Bag-of-Tricks-for-Image-Classification-with-Convolutional-Neural-Networks/)|
|66|R-FCNï¼šObject Detection via Region-based Fully Convolutional Networks|R-FCN|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/R-FCNï¼šObject%20Detection%20via%20Region-based%20Fully%20Convolutional%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2024/07/18/è®ºæ–‡é˜…è¯»-R-FCN-Object-Detection-via-Region-based-Fully-Convolutional-Networks/)|
|67|Deformable Convolutional Networks|DCN|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/Deformable%20Convolutional%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2024/07/25/è®ºæ–‡é˜…è¯»-Deformable-Convolutional-Networks/)|
|68|A Generic Camera Model and Calibration Method for Conventional, Wide-Angle, and Fish-Eye Lenses|é±¼çœ¼ç›¸æœºæ ¡æ­£|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/A%20Generic%20Camera%20Model%20and%20Calibration%20Method%20for%20Conventional%2C%20Wide-Angle%2C%20and%20Fish-Eye%20Lenses.pdf)|[ğŸ”—](http://shichaoxin.com/2024/07/30/è®ºæ–‡é˜…è¯»-A-Generic-Camera-Model-and-Calibration-Method-for-Conventional,-Wide-Angle,-and-Fish-Eye-Lenses/)|
|69|PP-YOLOï¼šAn Effective and Efficient Implementation of Object Detector|PP-YOLO|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/PP-YOLOï¼šAn%20Effective%20and%20Efficient%20Implementation%20of%20Object%20Detector.pdf)|[ğŸ”—](http://shichaoxin.com/2024/08/13/è®ºæ–‡é˜…è¯»-PP-YOLO-An-Effective-and-Efficient-Implementation-of-Object-Detector/)|
|70|UnitBoxï¼šAn Advanced Object Detection Network|UnitBoxï¼ŒIoU loss|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/UnitBoxï¼šAn%20Advanced%20Object%20Detection%20Network.pdf)|[ğŸ”—](http://shichaoxin.com/2024/08/16/è®ºæ–‡é˜…è¯»-UnitBox-An-Advanced-Object-Detection-Network/)|
|71|IoU-aware Single-stage Object Detector for Accurate Localization|IoU-aware loss|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/IoU-aware%20Single-stage%20Object%20Detector%20for%20Accurate%20Localization.pdf)|[ğŸ”—](http://shichaoxin.com/2024/08/16/è®ºæ–‡é˜…è¯»-IoU-aware-Single-stage-Object-Detector-for-Accurate-Localization/)|
|72|PP-YOLOv2ï¼šA Practical Object Detector|PP-YOLOv2|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/PP-YOLOv2ï¼šA%20Practical%20Object%20Detector.pdf)|[ğŸ”—](http://shichaoxin.com/2024/08/16/è®ºæ–‡é˜…è¯»-PP-YOLOv2-A-Practical-Object-Detector/)|
|73|BERTï¼šPre-training of Deep Bidirectional Transformers for Language Understanding|BERT|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/BERTï¼šPre-training%20of%20Deep%20Bidirectional%20Transformers%20for%20Language%20Understanding.pdf)|[ğŸ”—](http://shichaoxin.com/2024/08/12/è®ºæ–‡é˜…è¯»-BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding/)|
|74|Group Normalization|Batch Normï¼ŒLayer Normï¼ŒInstance Normï¼ŒGroup Norm|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/Group%20Normalization.pdf)|[ğŸ”—](http://shichaoxin.com/2024/08/20/è®ºæ–‡é˜…è¯»-Group-Normalization/)|
|75|FCOSï¼šFully Convolutional One-Stage Object Detection|FCOS|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/FCOSï¼šFully%20Convolutional%20One-Stage%20Object%20Detection.pdf)|[ğŸ”—](http://shichaoxin.com/2024/08/20/è®ºæ–‡é˜…è¯»-FCOS-Fully-Convolutional-One-Stage-Object-Detection/)|
|76|Machine Learning for High-Speed Corner Detection|FAST|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/Machine%20Learning%20for%20High-Speed%20Corner%20Detection.pdf)|[ğŸ”—](http://shichaoxin.com/2024/08/26/è®ºæ–‡é˜…è¯»-Machine-Learning-for-High-Speed-Corner-Detection/)|
|77|TOODï¼šTask-aligned One-stage Object Detection|TOOD|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/TOODï¼šTask-aligned%20One-stage%20Object%20Detection.pdf)|[ğŸ”—](http://shichaoxin.com/2024/08/29/è®ºæ–‡é˜…è¯»-TOOD-Task-aligned-One-stage-Object-Detection/)|
|78|Generalized Focal Lossï¼šLearning Qualified and Distributed Bounding Boxes for Dense Object Detection|GFLï¼ŒQFLï¼ŒDFL|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/Generalized%20Focal%20Lossï¼šLearning%20Qualified%20and%20Distributed%20Bounding%20Boxes%20for%20Dense%20Object%20Detection.pdf)|[ğŸ”—](http://shichaoxin.com/2024/09/04/è®ºæ–‡é˜…è¯»-Generalized-Focal-Loss-Learning-Qualified-and-Distributed-Bounding-Boxes-for-Dense-Object-Detection/)|
|79|BRISKï¼šBinary Robust invariant scalable keypoints|BRISK|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/BRISKï¼šBinary%20Robust%20invariant%20scalable%20keypoints.pdf)|[ğŸ”—](http://shichaoxin.com/2024/08/25/è®ºæ–‡é˜…è¯»-BRISK-Binary-Robust-invariant-scalable-keypoints/)|
|80|Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection|ATSS|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/Bridging%20the%20Gap%20Between%20Anchor-based%20and%20Anchor-free%20Detection%20via%20Adaptive%20Training%20Sample%20Selection.pdf)|[ğŸ”—](http://shichaoxin.com/2024/09/25/è®ºæ–‡é˜…è¯»-Bridging-the-Gap-Between-Anchor-based-and-Anchor-free-Detection-via-Adaptive-Training-Sample-Selection/)|
|81|VarifocalNetï¼šAn IoU-aware Dense Object Detector|VFNetï¼ŒVarifocal Lossï¼ŒIACS|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/VarifocalNetï¼šAn%20IoU-aware%20Dense%20Object%20Detector.pdf)|[ğŸ”—](http://shichaoxin.com/2024/09/25/è®ºæ–‡é˜…è¯»-VarifocalNet-An-IoU-aware-Dense-Object-Detector/)|
|82|PP-YOLOEï¼šAn evolved version of YOLO|PP-YOLOE|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/PP-YOLOEï¼šAn%20evolved%20version%20of%20YOLO.pdf)|[ğŸ”—](http://shichaoxin.com/2024/09/25/è®ºæ–‡é˜…è¯»-PP-YOLOE-An-evolved-version-of-YOLO/)|
|83|EfficientNetï¼šRethinking Model Scaling for Convolutional Neural Networks|EfficientNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/EfficientNetï¼šRethinking%20Model%20Scaling%20for%20Convolutional%20Neural%20Networks.pdf)|[ğŸ”—](http://shichaoxin.com/2024/12/19/è®ºæ–‡é˜…è¯»-EfficientNet-Rethinking-Model-Scaling-for-Convolutional-Neural-Networks/)|
|84|MobileNetsï¼šEfficient Convolutional Neural Networks for Mobile Vision Applications|MobileNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/MobileNetsï¼šEfficient%20Convolutional%20Neural%20Networks%20for%20Mobile%20Vision%20Applications.pdf)|[ğŸ”—](http://shichaoxin.com/2024/12/25/è®ºæ–‡é˜…è¯»-MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications/)|
|85|MobileNetV2ï¼šInverted Residuals and Linear Bottlenecks|MobileNetV2|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/MobileNetV2ï¼šInverted%20Residuals%20and%20Linear%20Bottlenecks.pdf)|[ğŸ”—](https://shichaoxin.com/2025/01/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MobileNetV2-Inverted-Residuals-and-Linear-Bottlenecks/)|
|86|An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection|VoVNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/An%20Energy%20and%20GPU-Computation%20Efficient%20Backbone%20Network%20for%20Real-Time%20Object%20Detection.pdf)|[ğŸ”—](https://shichaoxin.com/2025/04/14/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-An-Energy-and-GPU-Computation-Efficient-Backbone-Network-for-Real-Time-Object-Detection/)|
|87|Enriching Variety of Layer-wise Learning Information by Gradient Combination|PRN|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2024/Enriching%20Variety%20of%20Layer-wise%20Learning%20Information%20by%20Gradient%20Combination.pdf)|[ğŸ”—](https://shichaoxin.com/2025/04/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Enriching-Variety-of-Layer-wise-Learning-Information-by-Gradient-Combination/)|
|88|SSDï¼šSingle Shot MultiBox Detector|SSD|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2025/SSD%EF%BC%9ASingle%20Shot%20MultiBox%20Detector.pdf)|[ğŸ”—](https://shichaoxin.com/2025/06/12/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SSD-Single-Shot-MultiBox-Detector/)|
|89|Scaled-YOLOv4ï¼šScaling Cross Stage Partial Network|Scaled-YOLOv4ï¼ŒYOLOv4-CSPï¼ŒYOLOv4-Tinyï¼ŒYOLOv4-Large|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2025/Scaled-YOLOv4%EF%BC%9AScaling%20Cross%20Stage%20Partial%20Network.pdf)|[ğŸ”—](https://shichaoxin.com/2025/07/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Scaled-YOLOv4-Scaling-Cross-Stage-Partial-Network/)|
|90|You Only Learn One Representationï¼šUnified Network for Multiple Tasks|YOLOR|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2025/You%20Only%20Learn%20One%20Representation%EF%BC%9AUnified%20Network%20for%20Multiple%20Tasks.pdf)|[ğŸ”—](https://shichaoxin.com/2025/07/18/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-You-Only-Learn-One-Representation-Unified-Network-for-Multiple-Tasks/)|
|91|Designing Network Design Strategies Through Gradient Path Analysis|ELAN|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2025/Designing%20Network%20Design%20Strategies%20Through%20Gradient%20Path%20Analysis.pdf)|[ğŸ”—](https://shichaoxin.com/2025/07/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Designing-Network-Design-Strategies-Through-Gradient-Path-Analysis/)|
|92|ShuffleNetï¼šAn Extremely Efficient Convolutional Neural Network for Mobile Devices|ShuffleNet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2025/ShuffleNet%EF%BC%9AAn%20Extremely%20Efficient%20Convolutional%20Neural%20Network%20for%20Mobile%20Devices.pdf)|[ğŸ”—](https://shichaoxin.com/2025/08/13/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ShuffleNet-An-Extremely-Efficient-Convolutional-Neural-Network-for-Mobile-Devices/)|
|93|Squeeze-and-Excitation Networks|SENet|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2025/Squeeze-and-Excitation%20Networks.pdf)|[ğŸ”—](https://shichaoxin.com/2025/09/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Squeeze-and-Excitation-Networks/)|
|94|ShuffleNet V2ï¼šPractical Guidelines for Efficient CNN Architecture Design|ShuffleNet V2|[ğŸ”—](https://github.com/x-jeff/AI_Papers/blob/master/2025/ShuffleNet%20V2%EF%BC%9APractical%20Guidelines%20for%20Efficient%20CNN%20Architecture%20Design.pdf)|[ğŸ”—](https://shichaoxin.com/2025/09/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ShuffleNet-V2-Practical-Guidelines-for-Efficient-CNN-Architecture-Design/)|
